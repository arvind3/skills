# yaml-language-server: $schema=../skill-scenarios.schema.json
# Test scenarios for azure-ai-inference-ts skill evaluation
# Each scenario tests a specific usage pattern against acceptance criteria

config:
  model: gpt-4
  max_tokens: 2000
  temperature: 0.3

scenarios:
  # Basic Chat Completions with Entra ID
  - name: basic_chat_completion_default_credential
    prompt: |
      Create a basic Azure AI Inference chat completions example in TypeScript using
      DefaultAzureCredential. Include proper error checking with isUnexpected and
      print the response content.
    expected_patterns:
      - "DefaultAzureCredential"
      - "ModelClient"
      - '/chat/completions'
      - "isUnexpected"
      - "response.body.choices"
    forbidden_patterns:
      - 'new ModelClient'
      - 'ChatCompletionsClient'
      - 'from azure.ai.inference'
    tags:
      - basic
      - authentication
      - chat
    mock_response: |
      import ModelClient, { isUnexpected } from "@azure-rest/ai-inference";
      import { DefaultAzureCredential } from "@azure/identity";

      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new DefaultAzureCredential(),
      );

      const response = await client.path("/chat/completions").post({
        body: {
          messages: [
            { role: "system", content: "You are a helpful assistant." },
            { role: "user", content: "What is Azure AI?" },
          ],
        },
      });

      if (isUnexpected(response)) {
        throw response.body.error;
      }

      console.log(response.body.choices[0].message.content);

  # API Key Authentication
  - name: api_key_chat_completion
    prompt: |
      Create a TypeScript chat completions example using AzureKeyCredential with
      environment variables for the endpoint and credential.
    expected_patterns:
      - "AzureKeyCredential"
      - "process.env"
      - "ModelClient"
      - '/chat/completions'
    forbidden_patterns:
      - 'AzureKeyCredential\("'
      - 'new ModelClient'
    tags:
      - authentication
      - api-key
    mock_response: |
      import ModelClient, { isUnexpected } from "@azure-rest/ai-inference";
      import { AzureKeyCredential } from "@azure/core-auth";

      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new AzureKeyCredential(process.env.AZURE_INFERENCE_CREDENTIAL!),
      );

      const response = await client.path("/chat/completions").post({
        body: {
          messages: [
            { role: "system", content: "You are a helpful assistant." },
            { role: "user", content: "Give me one fact about Azure." },
          ],
        },
      });

      if (isUnexpected(response)) {
        throw response.body.error;
      }

      console.log(response.body.choices[0].message.content);

  # Embeddings
  - name: embeddings_basic
    prompt: |
      Create a TypeScript embeddings example using the REST client to embed
      a list of text inputs, then print the embedding length.
    expected_patterns:
      - "ModelClient"
      - '/embeddings'
      - "response.body.data"
      - "embedding.length"
    forbidden_patterns:
      - 'EmbeddingsClient'
      - 'client.embed'
    tags:
      - embeddings
      - basic
    mock_response: |
      import ModelClient, { isUnexpected } from "@azure-rest/ai-inference";
      import { DefaultAzureCredential } from "@azure/identity";

      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new DefaultAzureCredential(),
      );

      const response = await client.path("/embeddings").post({
        body: {
          input: ["first phrase", "second phrase", "third phrase"],
        },
      });

      if (isUnexpected(response)) {
        throw response.body.error;
      }

      for (const data of response.body.data) {
        console.log(`Embedding length: ${data.embedding.length}`);
      }

  # Streaming Chat Completions
  - name: streaming_chat_completions
    prompt: |
      Create a TypeScript streaming chat completions example using stream=true,
      asNodeStream(), and createSseStream to process events.
    expected_patterns:
      - "stream: true"
      - "asNodeStream"
      - "createSseStream"
      - "for await"
    forbidden_patterns:
      - "for update in response"
    tags:
      - streaming
      - chat
    mock_response: |
      import ModelClient from "@azure-rest/ai-inference";
      import { DefaultAzureCredential } from "@azure/identity";
      import { createSseStream } from "@azure/core-sse";
      import { IncomingMessage } from "node:http";

      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new DefaultAzureCredential(),
      );

      const response = await client
        .path("/chat/completions")
        .post({
          body: {
            messages: [
              { role: "system", content: "You are a helpful assistant." },
              { role: "user", content: "Write a short poem about Azure." },
            ],
            stream: true,
          },
        })
        .asNodeStream();

      const stream = response.body;
      if (!stream) {
        throw new Error("The response stream is undefined");
      }

      if (response.status !== "200") {
        throw new Error("Failed to get chat completions");
      }

      const sses = createSseStream(stream as IncomingMessage);

      for await (const event of sses) {
        if (event.data === "[DONE]") {
          break;
        }
        for (const choice of JSON.parse(event.data).choices) {
          process.stdout.write(choice.delta?.content ?? "");
        }
      }

  # Tool Calling Flow
  - name: tool_calling_flow
    prompt: |
      Create a TypeScript tool calling flow with a get_weather function tool.
      Show how to define tools and handle tool call responses.
    expected_patterns:
      - 'type: "function"'
      - "tools"
      - "toolCalls"
      - "tool_call_id"
    forbidden_patterns:
      - "FunctionToolDefinition"
      - "ChatCompletionsToolDefinition"
    tags:
      - tools
      - chat
    mock_response: |
      import ModelClient, { isUnexpected } from "@azure-rest/ai-inference";
      import { DefaultAzureCredential } from "@azure/identity";

      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new DefaultAzureCredential(),
      );

      const tools = [
        {
          type: "function" as const,
          function: {
            name: "get_weather",
            description: "Get current weather for a location",
            parameters: {
              type: "object",
              properties: {
                location: { type: "string", description: "City and state" },
              },
              required: ["location"],
            },
          },
        },
      ];

      function applyToolCall({ function: call, id }: { function: { name: string; arguments: string }; id: string }) {
        if (call.name === "get_weather") {
          const { location } = JSON.parse(call.arguments);
          return {
            role: "tool" as const,
            content: `The weather in ${location} is 72Â°F and sunny.`,
            toolCallId: id,
          };
        }
        throw new Error(`Unknown tool call: ${call.name}`);
      }

      const messages: any[] = [
        { role: "user", content: "What's the weather in Seattle?" },
      ];

      const response = await client.path("/chat/completions").post({
        body: { messages, tools },
      });

      if (isUnexpected(response)) {
        throw response.body.error;
      }

      const responseMessage = response.body.choices[0].message;
      if (responseMessage.toolCalls) {
        const toolMessages = responseMessage.toolCalls.map(applyToolCall);
        messages.push(responseMessage, ...toolMessages);

        const finalResponse = await client.path("/chat/completions").post({
          body: { messages },
        });

        if (!isUnexpected(finalResponse)) {
          console.log(finalResponse.body.choices[0].message.content);
        }
      }

  # Image Chat
  - name: chat_with_images
    prompt: |
      Create a TypeScript example that uses chat completions with an image URL
      to describe an image using a vision model.
    expected_patterns:
      - 'type: "image_url"'
      - "image_url"
      - '/chat/completions'
    tags:
      - vision
      - chat
    mock_response: |
      import ModelClient, { isUnexpected } from "@azure-rest/ai-inference";
      import { DefaultAzureCredential } from "@azure/identity";

      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new DefaultAzureCredential(),
      );

      const imageUrl = "https://upload.wikimedia.org/wikipedia/commons/example.jpg";

      const response = await client.path("/chat/completions").post({
        body: {
          messages: [
            {
              role: "user",
              content: [
                {
                  type: "image_url",
                  image_url: {
                    url: imageUrl,
                    detail: "auto",
                  },
                },
              ],
            },
            { role: "user", content: "Describe this image" },
          ],
        },
      });

      if (isUnexpected(response)) {
        throw response.body.error;
      }

      console.log(response.body.choices[0].message?.content);

  # Image Embeddings
  - name: image_embeddings
    prompt: |
      Create a TypeScript example that generates embeddings for an image
      using base64 encoding.
    expected_patterns:
      - '/images/embeddings'
      - "base64"
      - "readFileSync"
    tags:
      - embeddings
      - images
    mock_response: |
      import ModelClient, { isUnexpected } from "@azure-rest/ai-inference";
      import { DefaultAzureCredential } from "@azure/identity";
      import { readFileSync } from "node:fs";

      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new DefaultAzureCredential(),
      );

      function getImageDataUrl(imageFile: string, imageFormat: string): string {
        const imageBuffer = readFileSync(imageFile);
        const imageBase64 = imageBuffer.toString("base64");
        return `data:image/${imageFormat};base64,${imageBase64}`;
      }

      const image = getImageDataUrl("./sample.png", "png");

      const response = await client.path("/images/embeddings").post({
        body: {
          input: [{ image }],
        },
      });

      if (isUnexpected(response)) {
        throw response.body.error;
      }

      for (const data of response.body.data) {
        console.log(`Embedding length: ${data.embedding.length}`);
      }

  # OpenTelemetry Tracing
  - name: opentelemetry_tracing
    prompt: |
      Create a TypeScript example that sets up OpenTelemetry tracing for
      Azure AI Inference with a console exporter.
    expected_patterns:
      - "NodeTracerProvider"
      - "registerInstrumentations"
      - "createAzureSdkInstrumentation"
      - "tracingOptions"
    tags:
      - tracing
      - observability
    mock_response: |
      import {
        NodeTracerProvider,
        SimpleSpanProcessor,
        ConsoleSpanExporter,
      } from "@opentelemetry/sdk-trace-node";
      import { registerInstrumentations } from "@opentelemetry/instrumentation";
      import { createAzureSdkInstrumentation } from "@azure/opentelemetry-instrumentation-azure-sdk";
      import { context } from "@opentelemetry/api";
      import ModelClient from "@azure-rest/ai-inference";
      import { DefaultAzureCredential } from "@azure/identity";

      // Set up tracing
      const provider = new NodeTracerProvider();
      provider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter()));
      provider.register();

      registerInstrumentations({
        instrumentations: [createAzureSdkInstrumentation()],
      });

      // Create client and make traced request
      const client = ModelClient(
        process.env.AZURE_INFERENCE_ENDPOINT!,
        new DefaultAzureCredential(),
      );

      const response = await client.path("/chat/completions").post({
        body: {
          messages: [{ role: "user", content: "Hello" }],
        },
        tracingOptions: { tracingContext: context.active() },
      });
